{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW5-1: iris classification problem (tf.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 46ms/step - loss: 1.0841 - accuracy: 0.3167 - val_loss: 0.8766 - val_accuracy: 0.7667\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8130 - accuracy: 0.7000 - val_loss: 0.6692 - val_accuracy: 0.8000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.7250 - val_loss: 0.5425 - val_accuracy: 0.8333\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5953 - accuracy: 0.7583 - val_loss: 0.4649 - val_accuracy: 0.8333\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5228 - accuracy: 0.7833 - val_loss: 0.4147 - val_accuracy: 0.8333\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4792 - accuracy: 0.8083 - val_loss: 0.3784 - val_accuracy: 0.8667\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4420 - accuracy: 0.8250 - val_loss: 0.3490 - val_accuracy: 0.9000\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4230 - accuracy: 0.8333 - val_loss: 0.3237 - val_accuracy: 0.9000\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4016 - accuracy: 0.8167 - val_loss: 0.2981 - val_accuracy: 0.9000\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3562 - accuracy: 0.8417 - val_loss: 0.2779 - val_accuracy: 0.9000\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3589 - accuracy: 0.8250 - val_loss: 0.2608 - val_accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3597 - accuracy: 0.8417 - val_loss: 0.2439 - val_accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3146 - accuracy: 0.8500 - val_loss: 0.2299 - val_accuracy: 0.9000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3234 - accuracy: 0.8500 - val_loss: 0.2192 - val_accuracy: 0.9000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3163 - accuracy: 0.8917 - val_loss: 0.2079 - val_accuracy: 0.9000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2965 - accuracy: 0.8667 - val_loss: 0.1966 - val_accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2836 - accuracy: 0.8917 - val_loss: 0.1840 - val_accuracy: 0.9667\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2557 - accuracy: 0.9083 - val_loss: 0.1732 - val_accuracy: 0.9333\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2463 - accuracy: 0.9167 - val_loss: 0.1603 - val_accuracy: 0.9667\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2385 - accuracy: 0.8917 - val_loss: 0.1518 - val_accuracy: 0.9667\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2246 - accuracy: 0.9417 - val_loss: 0.1423 - val_accuracy: 0.9667\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2323 - accuracy: 0.9250 - val_loss: 0.1358 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2106 - accuracy: 0.9500 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2184 - accuracy: 0.9083 - val_loss: 0.1282 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2146 - accuracy: 0.9333 - val_loss: 0.1285 - val_accuracy: 0.9667\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1710 - accuracy: 0.9333 - val_loss: 0.1105 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1996 - accuracy: 0.9250 - val_loss: 0.1101 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1531 - accuracy: 0.9500 - val_loss: 0.1031 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1966 - accuracy: 0.9250 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1791 - accuracy: 0.9417 - val_loss: 0.1038 - val_accuracy: 0.9667\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1488 - accuracy: 0.9417 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1585 - accuracy: 0.9333 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1690 - accuracy: 0.9500 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1283 - accuracy: 0.9500 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1413 - accuracy: 0.9333 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1178 - accuracy: 0.9583 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1249 - accuracy: 0.9667 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1089 - accuracy: 0.9583 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1195 - accuracy: 0.9667 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1263 - accuracy: 0.9500 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1066 - accuracy: 0.9583 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1301 - accuracy: 0.9583 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0977 - accuracy: 0.9750 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0900 - accuracy: 0.9750 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1059 - accuracy: 0.9667 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9750 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0939 - accuracy: 0.9667 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.9417 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0904 - accuracy: 0.9583 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0440 - accuracy: 1.0000\n",
      "Test accuracy: 1.0000\n",
      "啟動 TensorBoard 命令: tensorboard --logdir=logs/tfkeras\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 1. 清除舊日誌和 TensorBoard 緩存\n",
    "log_dir = \"logs/tfkeras\"\n",
    "cache_dir = os.path.expanduser('~/.tensorboard-info')\n",
    "\n",
    "# 刪除舊日誌和緩存\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)  # 清除舊 TensorBoard 日誌\n",
    "\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)  # 清除 TensorBoard 緩存檔案\n",
    "\n",
    "# 2. 加載 Iris 資料集\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 3. 資料標準化\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 4. One-hot 編碼\n",
    "y = tf.keras.utils.to_categorical(y, 3)\n",
    "\n",
    "# 5. 資料集切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. 定義模型\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# 7. 編譯模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 8. TensorBoard 設置 (覆蓋模式)\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "\n",
    "# 9. 訓練模型\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "# 10. 評估模型\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 11. TensorBoard 啟動命令\n",
    "print(f\"啟動 TensorBoard 命令: tensorboard --logdir={log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW5-1: iris classification problem (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 8.3048, Train Acc: 0.4083, Val Loss: 1.8062, Val Acc: 0.7000\n",
      "Epoch 2/50, Train Loss: 6.9780, Train Acc: 0.6583, Val Loss: 1.3869, Val Acc: 0.7333\n",
      "Epoch 3/50, Train Loss: 5.1680, Train Acc: 0.7333, Val Loss: 0.9087, Val Acc: 0.8667\n",
      "Epoch 4/50, Train Loss: 3.3617, Train Acc: 0.8833, Val Loss: 0.5843, Val Acc: 0.9333\n",
      "Epoch 5/50, Train Loss: 2.4860, Train Acc: 0.9000, Val Loss: 0.4192, Val Acc: 0.9000\n",
      "Epoch 6/50, Train Loss: 1.9125, Train Acc: 0.9167, Val Loss: 0.2872, Val Acc: 1.0000\n",
      "Epoch 7/50, Train Loss: 1.4931, Train Acc: 0.9500, Val Loss: 0.2122, Val Acc: 1.0000\n",
      "Epoch 8/50, Train Loss: 1.1427, Train Acc: 0.9500, Val Loss: 0.1675, Val Acc: 1.0000\n",
      "Epoch 9/50, Train Loss: 0.8859, Train Acc: 0.9500, Val Loss: 0.1366, Val Acc: 0.9667\n",
      "Epoch 10/50, Train Loss: 0.7383, Train Acc: 0.9583, Val Loss: 0.1383, Val Acc: 0.9667\n",
      "Epoch 11/50, Train Loss: 0.6284, Train Acc: 0.9500, Val Loss: 0.1184, Val Acc: 0.9667\n",
      "Epoch 12/50, Train Loss: 0.6802, Train Acc: 0.9583, Val Loss: 0.1255, Val Acc: 0.9667\n",
      "Epoch 13/50, Train Loss: 0.5837, Train Acc: 0.9667, Val Loss: 0.1081, Val Acc: 0.9667\n",
      "Epoch 14/50, Train Loss: 0.6757, Train Acc: 0.9583, Val Loss: 0.0953, Val Acc: 0.9667\n",
      "Epoch 15/50, Train Loss: 0.6587, Train Acc: 0.9750, Val Loss: 0.0789, Val Acc: 1.0000\n",
      "Epoch 16/50, Train Loss: 0.5058, Train Acc: 0.9750, Val Loss: 0.0868, Val Acc: 0.9667\n",
      "Epoch 17/50, Train Loss: 0.6153, Train Acc: 0.9583, Val Loss: 0.0903, Val Acc: 0.9667\n",
      "Epoch 18/50, Train Loss: 0.4701, Train Acc: 0.9750, Val Loss: 0.0793, Val Acc: 1.0000\n",
      "Epoch 19/50, Train Loss: 0.5434, Train Acc: 0.9667, Val Loss: 0.0779, Val Acc: 0.9667\n",
      "Epoch 20/50, Train Loss: 0.4982, Train Acc: 0.9583, Val Loss: 0.0705, Val Acc: 1.0000\n",
      "Epoch 21/50, Train Loss: 0.5724, Train Acc: 0.9583, Val Loss: 0.0715, Val Acc: 0.9667\n",
      "Epoch 22/50, Train Loss: 0.4985, Train Acc: 0.9667, Val Loss: 0.0612, Val Acc: 1.0000\n",
      "Epoch 23/50, Train Loss: 0.4831, Train Acc: 0.9750, Val Loss: 0.0646, Val Acc: 1.0000\n",
      "Epoch 24/50, Train Loss: 0.6262, Train Acc: 0.9667, Val Loss: 0.0760, Val Acc: 0.9667\n",
      "Epoch 25/50, Train Loss: 0.4090, Train Acc: 0.9833, Val Loss: 0.0672, Val Acc: 1.0000\n",
      "Epoch 26/50, Train Loss: 0.4952, Train Acc: 0.9750, Val Loss: 0.0672, Val Acc: 1.0000\n",
      "Epoch 27/50, Train Loss: 0.6252, Train Acc: 0.9583, Val Loss: 0.0774, Val Acc: 0.9667\n",
      "Epoch 28/50, Train Loss: 0.3958, Train Acc: 0.9750, Val Loss: 0.0635, Val Acc: 1.0000\n",
      "Epoch 29/50, Train Loss: 0.4603, Train Acc: 0.9833, Val Loss: 0.0575, Val Acc: 1.0000\n",
      "Epoch 30/50, Train Loss: 0.4771, Train Acc: 0.9750, Val Loss: 0.0534, Val Acc: 1.0000\n",
      "Epoch 31/50, Train Loss: 0.4180, Train Acc: 0.9833, Val Loss: 0.0528, Val Acc: 1.0000\n",
      "Epoch 32/50, Train Loss: 0.4428, Train Acc: 0.9750, Val Loss: 0.0579, Val Acc: 1.0000\n",
      "Epoch 33/50, Train Loss: 0.4687, Train Acc: 0.9833, Val Loss: 0.0708, Val Acc: 1.0000\n",
      "Epoch 34/50, Train Loss: 0.3908, Train Acc: 0.9750, Val Loss: 0.0714, Val Acc: 0.9667\n",
      "Epoch 35/50, Train Loss: 0.4555, Train Acc: 0.9667, Val Loss: 0.0582, Val Acc: 1.0000\n",
      "Epoch 36/50, Train Loss: 0.5556, Train Acc: 0.9833, Val Loss: 0.0490, Val Acc: 1.0000\n",
      "Epoch 37/50, Train Loss: 0.4319, Train Acc: 0.9833, Val Loss: 0.0478, Val Acc: 1.0000\n",
      "Epoch 38/50, Train Loss: 0.3862, Train Acc: 0.9833, Val Loss: 0.0514, Val Acc: 1.0000\n",
      "Epoch 39/50, Train Loss: 0.4132, Train Acc: 0.9667, Val Loss: 0.0533, Val Acc: 1.0000\n",
      "Epoch 40/50, Train Loss: 0.3774, Train Acc: 0.9833, Val Loss: 0.0522, Val Acc: 1.0000\n",
      "Epoch 41/50, Train Loss: 0.3966, Train Acc: 0.9833, Val Loss: 0.0475, Val Acc: 1.0000\n",
      "Epoch 42/50, Train Loss: 0.4136, Train Acc: 0.9750, Val Loss: 0.0476, Val Acc: 1.0000\n",
      "Epoch 43/50, Train Loss: 0.7111, Train Acc: 0.9667, Val Loss: 0.0474, Val Acc: 1.0000\n",
      "Epoch 44/50, Train Loss: 0.3769, Train Acc: 0.9750, Val Loss: 0.0590, Val Acc: 1.0000\n",
      "Epoch 45/50, Train Loss: 0.5166, Train Acc: 0.9667, Val Loss: 0.0482, Val Acc: 1.0000\n",
      "Epoch 46/50, Train Loss: 0.6099, Train Acc: 0.9750, Val Loss: 0.0527, Val Acc: 1.0000\n",
      "Epoch 47/50, Train Loss: 0.3302, Train Acc: 0.9917, Val Loss: 0.0705, Val Acc: 0.9667\n",
      "Epoch 48/50, Train Loss: 0.5835, Train Acc: 0.9667, Val Loss: 0.0463, Val Acc: 1.0000\n",
      "Epoch 49/50, Train Loss: 0.4390, Train Acc: 0.9750, Val Loss: 0.0641, Val Acc: 1.0000\n",
      "Epoch 50/50, Train Loss: 0.3887, Train Acc: 0.9833, Val Loss: 0.0548, Val Acc: 1.0000\n",
      "啟動 TensorBoard 命令: tensorboard --logdir=logs/pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 1. 清除舊日誌\n",
    "log_dir = \"logs/pytorch\"\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)  # 移除舊 TensorBoard 日誌\n",
    "os.makedirs(log_dir)\n",
    "\n",
    "# 2. 資料準備\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 標準化資料\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 資料切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 轉為 Tensor\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 3. 定義模型 \n",
    "class IrisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = IrisModel().to(device)\n",
    "\n",
    "# 4. 設定損失函數與優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 5. TensorBoard 設定\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# 6. 訓練模型\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    # 記錄訓練數據\n",
    "    train_acc = correct / total\n",
    "    writer.add_scalar('Loss/train', train_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    \n",
    "    # 驗證模型\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    val_acc = correct / total\n",
    "    writer.add_scalar('Loss/val', val_loss / len(test_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "#  啟動 TensorBoard\n",
    "print(f\"啟動 TensorBoard 命令: tensorboard --logdir={log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW5-1: iris classification problem (pytorch lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | Sequential         | 193    | train\n",
      "1 | criterion | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "193       Trainable params\n",
      "0         Non-trainable params\n",
      "193       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jing5\\anaconda3\\envs\\555\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\jing5\\anaconda3\\envs\\555\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\jing5\\anaconda3\\envs\\555\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 8/8 [00:00<00:00, 91.41it/s, v_num=0] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 8/8 [00:00<00:00, 86.47it/s, v_num=0]\n",
      "啟動 TensorBoard 命令: tensorboard --logdir=logs/lightning\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 1. 清除舊日誌\n",
    "log_dir = \"logs/lightning\"\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)  # 移除舊 TensorBoard 日誌\n",
    "os.makedirs(log_dir)\n",
    "\n",
    "# 2. 資料準備\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 標準化資料\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 資料切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 轉為 Tensor\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 3. 定義模型\n",
    "class IrisModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(IrisModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = self.train_acc(y_hat, y)\n",
    "\n",
    "        # 記錄 TensorBoard\n",
    "        self.log(\"Loss/train\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"Accuracy/train\", acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = self.val_acc(y_hat, y)\n",
    "\n",
    "        # 記錄 TensorBoard\n",
    "        self.log(\"Loss/val\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"Accuracy/val\", acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "# 4. 設定 Callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"Loss/val\",\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"Loss/val\",\n",
    "    patience=10,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# 5. 訓練與驗證\n",
    "model = IrisModel()\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    default_root_dir=log_dir,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)\n",
    "\n",
    "# 6. 啟動 TensorBoard\n",
    "print(f\"啟動 TensorBoard 命令: tensorboard --logdir={log_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "555",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
